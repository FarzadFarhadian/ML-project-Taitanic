# ML-project-Taitanic
---

This project is a machine learning-based Titanic survival predictor that uses various machine learning algorithms such as K-Nearest Neighbors (KNN) and Support Vector Machines (SVM) to predict whether a passenger on the Titanic survived or not. The project was developed using Python in a Jupyter Notebook environment and includes the following key stages:

1. Import Data: The Titanic dataset was imported into the Jupyter Notebook using Pandas.

2. Clean Data: The dataset was cleaned to remove duplicates, missing values, and other inconsistencies using various Pandas functions.

3. Exploratory Data Analysis (EDA): The dataset was analyzed to identify trends, relationships, and patterns using functions such as correlation matrices and scatter plots.

4. Feature Engineering: New features were created from the existing data to improve the performance of machine learning models. This included tasks such as one-hot encoding, feature scaling, and text preprocessing.

5. Model Building: Two machine learning algorithms were used to build models based on the features of the Titanic dataset. The models were trained and tested using Scikit-learn. The first model used the K-Nearest Neighbors algorithm, while the second model used Support Vector Machines.

6. Model Evaluation: The performance of the models was evaluated using metrics such as accuracy, precision, recall, and F1 score.

7. Model Tuning: The models were refined and improved based on the evaluation results to increase their accuracy and effectiveness.

The code and files for this project can be found in the GitHub repository, which includes a Jupyter Notebook file detailing the data cleaning, EDA, feature engineering, model building, and model evaluation stages. The notebook also includes detailed explanations and comments to guide users through the code.
